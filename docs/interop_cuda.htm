<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9.1"/>
<title>Interoperability with CUDA</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="afw.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="arrayfire.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table width="100%">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="arrayfire_logo.png"/>
  </td>
	 <td id="gsearch">
   <div><script>
	    (function() {
        var cx = '004356362924927882526:zup3ehe-7bs';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
	    var s = document.getElementsByTagName('script')[0];
	    s.parentNode.insertBefore(gcse, s);
	  })();
  </script>
  <gcse:search></gcse:search>
</div>
	 </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.htm"><span>Main&#160;Page</span></a></li>
      <li><a href="usergroup0.htm"><span>Tutorials</span></a></li>
      <li><a href="modules.htm"><span>Functions</span></a></li>
      <li><a href="releasenotes.htm"><span>Release&#160;Notes</span></a></li>
      <li><a href="examples.htm"><span>Examples</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('interop_cuda.htm','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Interoperability with CUDA </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>As extensive as ArrayFire is, there are a few cases where you are still working with custom <a class="el" href="interop_cuda.htm">CUDA</a> or <a class="el" href="interop_opencl.htm">OpenCL</a> kernels. For example, you may want to integrate ArrayFire into an existing code base for productivity or you may want to keep it around the old implementation for testing purposes. Arrayfire provides a number of functions that allow it to work alongside native CUDA commands. In this tutorial we are going to talk about how to use native CUDA memory operations and integrate custom CUDA kernels into ArrayFire in a seamless fashion.</p>
<h1>In and Out of Arrayfire</h1>
<p>First, let's consider the following code and then break it down bit by bit.</p>
<div class="fragment"><div class="line"><span class="keywordtype">int</span> main() {</div>
<div class="line">    <a class="code" href="classaf_1_1array.htm">af::array</a> x = <a class="code" href="group__data__func__randu.htm#ga15a5110a447509cab9589b2ad56c5e55">randu</a>(num);</div>
<div class="line">    <a class="code" href="classaf_1_1array.htm">af::array</a> y = <a class="code" href="group__data__func__randu.htm#ga15a5110a447509cab9589b2ad56c5e55">randu</a>(num);</div>
<div class="line"></div>
<div class="line">    <span class="keywordtype">float</span> *d_x = x.<a class="code" href="group__device__func__device.htm#ga93c855ccd22d37cf90d32aef5ac75030">device</a>&lt;<span class="keywordtype">float</span>&gt;();</div>
<div class="line">    <span class="keywordtype">float</span> *d_y = y.<a class="code" href="group__device__func__device.htm#ga93c855ccd22d37cf90d32aef5ac75030">device</a>&lt;<span class="keywordtype">float</span>&gt;();</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Launch kernel to do the following operations</span></div>
<div class="line">    <span class="comment">// y = sin(x)^2 + cos(x)^2</span></div>
<div class="line">    launch_simple_kernel(d_x, d_y, num);</div>
<div class="line"></div>
<div class="line">    x.<a class="code" href="classaf_1_1array.htm#ab896fcbef7ce95ee1dc6a8c633240ee6">unlock</a>();</div>
<div class="line">    y.<a class="code" href="classaf_1_1array.htm#ab896fcbef7ce95ee1dc6a8c633240ee6">unlock</a>();</div>
<div class="line"></div>
<div class="line">    <span class="comment">// check for errors, should be 0,</span></div>
<div class="line">    <span class="comment">// since sin(x)^2 + cos(x)^2 == 1</span></div>
<div class="line">    <span class="keywordtype">float</span> err = <a class="code" href="group__reduce__func__sum.htm#ga964a8e7e78dd6d8f4d20c17edf82dbf5">af::sum</a>(<a class="code" href="group__arith__func__abs.htm#ga23aa8c28a5ffa9368cc92abb143f5eaa">af::abs</a>(y-1));</div>
<div class="line">    printf(<span class="stringliteral">&quot;Error: %f\n&quot;</span>, err);</div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
</div><!-- fragment --><h2>Breakdown</h2>
<p>Most kernels require an input. In this case, we created a random uniform array <code>x</code>. We also go ahead and prepare the output array. The necessary memory required is allocated in array <code>y</code> before the kernel launch.</p>
<div class="fragment"><div class="line"><a class="code" href="classaf_1_1array.htm">af::array</a> x = <a class="code" href="group__data__func__randu.htm#ga15a5110a447509cab9589b2ad56c5e55">randu</a>(num);</div>
<div class="line"><a class="code" href="classaf_1_1array.htm">af::array</a> y = <a class="code" href="group__data__func__randu.htm#ga15a5110a447509cab9589b2ad56c5e55">randu</a>(num);</div>
</div><!-- fragment --><p>In this example, the output is the same size as in the input. Note that the actual output data type is not specified. For such cases, ArrayFire assumes the data type is single precision floating point (<a class="el" href="defines_8h.htm#a023d8ac325fb14f1712a52fb0940b1d5a82ea90203678bdd0b547068f0a76524b">af::f32</a>). If necessary, the data type can be specified at the end of the array(..) constructor. Once you have the input and output arrays, you will need to extract the device pointers / objects using <a class="el" href="group__device__func__device.htm#ga93c855ccd22d37cf90d32aef5ac75030">af::array::device()</a> method in the following manner.</p>
<div class="fragment"><div class="line"><span class="keywordtype">float</span> *d_x = x.<a class="code" href="group__device__func__device.htm#ga93c855ccd22d37cf90d32aef5ac75030">device</a>&lt;<span class="keywordtype">float</span>&gt;();</div>
<div class="line"><span class="keywordtype">float</span> *d_y = y.<a class="code" href="group__device__func__device.htm#ga93c855ccd22d37cf90d32aef5ac75030">device</a>&lt;<span class="keywordtype">float</span>&gt;();</div>
</div><!-- fragment --><p>Accesing the device pointer in this manner internally sets a flag prohibiting the arrayfire object from further managing the memory. Ownership will need to be returned to the <a class="el" href="classaf_1_1array.htm" title="A multi dimensional data container. ">af::array</a> object once we are finished using it.</p>
<div class="fragment"><div class="line"><span class="comment">// Launch kernel to do the following operations</span></div>
<div class="line"><span class="comment">// y = sin(x)^2 + cos(x)^2</span></div>
<div class="line">launch_simple_kernel(d_x, d_y, num);</div>
</div><!-- fragment --><p>The function <code>launch_simple_kernel</code> handles the launching of your custom kernel. We will have a look at how to do this in CUDA later in the post.</p>
<p>Once you have finished your computations, you have to tell ArrayFire to take control of the memory objects.</p>
<div class="fragment"><div class="line">x.<a class="code" href="classaf_1_1array.htm#ab896fcbef7ce95ee1dc6a8c633240ee6">unlock</a>();</div>
<div class="line">y.<a class="code" href="classaf_1_1array.htm#ab896fcbef7ce95ee1dc6a8c633240ee6">unlock</a>();</div>
</div><!-- fragment --><p>This is a very crucial step as ArrayFire believes the user is still in control of the pointer. This means that ArrayFire will not perform garbage collection on these objects resulting in memory leaks. You can now proceed with the rest of the program.</p>
<p>In our particular example, we are just performing an error check and exiting.</p>
<div class="fragment"><div class="line"><span class="comment">// check for errors, should be 0,</span></div>
<div class="line"><span class="comment">// since sin(x)^2 + cos(x)^2 == 1</span></div>
<div class="line"><span class="keywordtype">float</span> err = <a class="code" href="group__reduce__func__sum.htm#ga964a8e7e78dd6d8f4d20c17edf82dbf5">af::sum</a>(<a class="code" href="group__arith__func__abs.htm#ga23aa8c28a5ffa9368cc92abb143f5eaa">af::abs</a>(y-1));</div>
<div class="line">printf(<span class="stringliteral">&quot;Error: %f\n&quot;</span>, err);</div>
</div><!-- fragment --><h1>Launching a CUDA kernel</h1>
<p>Arrayfire provides a collection of CUDA interoperability functions for additional capabilities when working with custom CUDA code. To use them, we need to include the <a class="el" href="cuda_8h.htm">cuda.h</a> header.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cuda_8h.htm">af/cuda.h</a>&gt;</span></div>
</div><!-- fragment --><p>The first thing these headers allow us to do are to get and set the active device using native CUDA device ids. This is achieved through the following functions:</p>
<blockquote class="doxtable">
<p><code>static int <a class="el" href="group__cuda__mat.htm#ga59b163ea391ea856a25693e2567b0ce5" title="Get the native device id of the CUDA device with id in ArrayFire context. ">afcu::getNativeId</a> (int id)</code> &ndash; Get the native device id of the CUDA device with <code>id</code> in the ArrayFire context. </p>
</blockquote>
<blockquote class="doxtable">
<p><code>static void <a class="el" href="group__cuda__mat.htm#ga6178cfc0ae2dbc311e9462d67d0f6c32" title="Set the CUDA device with given native id as the active device for ArrayFire. ">afcu::setNativeId</a> (int nativeId)</code> &ndash; Set the CUDA device with given native <code>id</code> as the active device for ArrayFire. </p>
</blockquote>
<p>The headers also allow us to retrieve the CUDA stream used internally inside Arrayfire.</p>
<blockquote class="doxtable">
<p><code>static cudaStream_t <a class="el" href="group__cuda__mat.htm#gaec1dc4c2aa935dc61889f23248c8450d" title="Get the stream for the CUDA device with id in ArrayFire context. ">afcu::getStream(int id)</a></code> &ndash; Get the stream for the CUDA device with <code>id</code> in ArrayFire context. </p>
</blockquote>
<p>These functions are available within the <a class="el" href="namespaceafcu.htm">afcu</a> namespace and equal C variants can be found in the full <a class="el" href="group__cuda__mat.htm">af/cuda.h documentation</a>.</p>
<p>To integrate a CUDA kernel into an ArrayFire code base, we first need to get the CUDA stream associated with arrayfire. Once we have this stream, we need to make sure Arrayfire is done with all computation before we can call our custom kernel to avoid out of order execution. We can do this with some variant of <code>cudaStreamQuery(af_stream)</code> or <code>cudaStreamSynchronize(af_stream)</code> or instead, we could add our kernel launch to Arrayfire's stream as shown below. Once we get the associated stream, all that is left is setting up the usual launch configuration parameters, launching the kernel and wait for the computations to finish:</p>
<div class="fragment"><div class="line">__global__</div>
<div class="line"><span class="keyword">static</span> <span class="keywordtype">void</span> simple_kernel(<span class="keywordtype">float</span> *d_y,</div>
<div class="line">                          <span class="keyword">const</span> <span class="keywordtype">float</span> *d_x,</div>
<div class="line">                          <span class="keyword">const</span> <span class="keywordtype">int</span> num)</div>
<div class="line">{</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> <span class="keywordtype">id</span> = blockIdx.x * blockDim.x + threadIdx.x;</div>
<div class="line"></div>
<div class="line">    <span class="keywordflow">if</span> (<span class="keywordtype">id</span> &lt; num) {</div>
<div class="line">        <span class="keywordtype">float</span> x = d_x[id];</div>
<div class="line">        <span class="keywordtype">float</span> sin_x = <a class="code" href="group__arith__func__sin.htm#gac6fdb44f59fbbffdc55c9c4af29e08f4">sin</a>(x);</div>
<div class="line">        <span class="keywordtype">float</span> cos_x = <a class="code" href="group__arith__func__cos.htm#ga00be564e1f588df68288d2dec8578cb6">cos</a>(x);</div>
<div class="line">        d_y[id] = (sin_x * sin_x) + (cos_x * cos_x);</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> <span class="keyword">inline</span> launch_simple_kernel(<span class="keywordtype">float</span> *d_y,</div>
<div class="line">                                 <span class="keyword">const</span> <span class="keywordtype">float</span> *d_x,</div>
<div class="line">                                 <span class="keyword">const</span> <span class="keywordtype">int</span> num)</div>
<div class="line">{</div>
<div class="line">    <span class="comment">// Get Arrayfire&#39;s internal CUDA stream</span></div>
<div class="line">    <span class="keywordtype">int</span> af_id = <a class="code" href="group__device__func__get.htm#ga4dfe3f90475b735384f8b28cf2b19a11">af::getDevice</a>();</div>
<div class="line">    cudaStream_t af_stream = <a class="code" href="group__cuda__mat.htm#gaec1dc4c2aa935dc61889f23248c8450d">afcu::getStream</a>(af_id);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Set launch configuration</span></div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> threads = 256;</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> blocks = (num / threads) + ((num % threads) ? 1 : 0);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// execute kernel on Arrayfire&#39;s stream,</span></div>
<div class="line">    <span class="comment">// ensuring all previous arrayfire operations complete</span></div>
<div class="line">    simple_kernel&lt;&lt;&lt;blocks, threads, 0, af_stream&gt;&gt;&gt;(d_y, d_x, num);</div>
<div class="line">}</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- doc-content -->
</div>
</div>
</div>
</div>
</div>
<!--Google Analytics-->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-5076919-1']);
  _gaq.push(['_setDomainName', '.arrayfire.com']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!--Spectate-->
<script type="text/javascript">
  sAId = "151";
  sCId = "688";
  (function() {
    function async_load(){
      var s = document.createElement('script'); s.type = 'text/javascript';
      s.src = (('https:' == document.location.protocol) ? "https://ssl" : "http://cdn") + ".spectate.com/s.js";
      var c = document.getElementsByTagName('script')[0]; c.parentNode.insertBefore(s, c);
    }
    if(window.attachEvent) { window.attachEvent('onload', async_load); }
    else { window.addEventListener('load', async_load, false); }
  })();
</script>
<!--Adroll-->
<script type="text/javascript">
adroll_adv_id = "ZRWI4W4RTRHENOWGXZY5JQ";
adroll_pix_id = "QLXGBK3MSFB6LOL6PES2MT";
(function () {
var oldonload = window.onload;
window.onload = function(){
   __adroll_loaded=true;
   var scr = document.createElement("script");
   var host = (("https:" == document.location.protocol) ? "https://s.adroll.com" : "http://a.adroll.com");
   scr.setAttribute('async', 'true');
   scr.type = "text/javascript";
   scr.src = host + "/j/roundtrip.js";
   ((document.getElementsByTagName('head') || [null])[0] ||
    document.getElementsByTagName('script')[0].parentNode).appendChild(scr);
   if(oldonload){oldonload()}};
}());
</script>
</body>
</html>
